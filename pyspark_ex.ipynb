{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pyspark-ex.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPp84A3BeDz1Tnnh8wp3PXJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klnsuman/NLP-/blob/main/pyspark_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc_U6e3OWSBQ",
        "outputId": "a1e4cc8d-1908-40fb-e53f-c7783c53efa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 35 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 38.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=4d29d444c0b43e3f90398d49eb7d52db83ef727e847d525eb2ade9a012f505a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "data = [('James','','Smith','1991-04-01','M',3000),\n",
        "  ('Michael','Rose','','2000-05-19','M',4000),\n",
        "  ('Robert','','Williams','1978-09-05','M',4000),\n",
        "  ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "  ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "]\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master(\"local[1]\") \\\n",
        "    .appName(\"SparkByExamples.com\") \\\n",
        "    .getOrCreate()\n",
        "    \n",
        "columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "df = spark.createDataFrame(data=data, schema = columns)\n"
      ],
      "metadata": {
        "id": "JCppXcpaWYQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cOE1l1AWopi",
        "outputId": "b8f2eeaf-e172-4a58-9b6d-d6e599d7e6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+--------+----------+------+------+\n",
            "|firstname|middlename|lastname|       dob|gender|salary|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "|    James|          |   Smith|1991-04-01|     M|  3000|\n",
            "|  Michael|      Rose|        |2000-05-19|     M|  4000|\n",
            "|   Robert|          |Williams|1978-09-05|     M|  4000|\n",
            "|    Maria|      Anne|   Jones|1967-12-01|     F|  4000|\n",
            "|      Jen|      Mary|   Brown|1980-02-17|     F|    -1|\n",
            "+---------+----------+--------+----------+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spark-nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YjDRLTCW0-N",
        "outputId": "4a41d81f-2696-4498-8c8d-55c7d6b23f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spark-nlp\n",
            "  Downloading spark_nlp-3.4.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▎                             | 10 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 30 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 40 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 61 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 71 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 92 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 102 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 112 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 122 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 133 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 142 kB 6.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: spark-nlp\n",
            "Successfully installed spark-nlp-3.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile spark-mllib-tfidf.py\n",
        "from __future__ import print_function\n",
        " \n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .appName(\"TfIdf Example\")\\\n",
        "        .getOrCreate()\n",
        " \n",
        "    sentenceData = spark.createDataFrame([\n",
        "        (0.0, \"Welcome to TutorialKart.\"),\n",
        "        (0.0, \"Learn Spark at TutorialKart.\"),\n",
        "        (1.0, \"Spark Mllib has TF-IDF.\")\n",
        "    ], [\"label\", \"sentence\"])\n",
        " \n",
        "    tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
        "    wordsData = tokenizer.transform(sentenceData)\n",
        " \n",
        "    hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
        "    featurizedData = hashingTF.transform(wordsData)\n",
        "    # alternatively, CountVectorizer can also be used to get term frequency vectors\n",
        " \n",
        "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "    idfModel = idf.fit(featurizedData)\n",
        "    rescaledData = idfModel.transform(featurizedData)\n",
        " \n",
        "    rescaledData.select(\"label\", \"features\").show()\n",
        " \n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AzuDBH_a_UC",
        "outputId": "cfdf3b68-929e-4e3a-dd97-f2d124969d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing spark-mllib-tfidf.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!spark-submit spark-mllib-tfidf.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I80pgFUgbASL",
        "outputId": "ba3253a5-b40c-4275-ef00-fb96271781d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: An illegal reflective access operation has occurred\n",
            "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
            "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
            "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
            "WARNING: All illegal access operations will be denied in a future release\n"
          ]
        }
      ]
    }
  ]
}